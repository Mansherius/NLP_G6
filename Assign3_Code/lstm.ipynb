{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts\n",
      "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
      "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
      "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
      "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
      "4  ENTJ  'You're fired.|||That's another silly misconce...\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('mbti_1.csv', encoding='latin1', on_bad_lines='skip')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts\n",
      "0  INFJ  ['http://www.youtube.com/watch?v=qsXHcwe3krw, ...\n",
      "1  ENTP  ['I'm finding the lack of me in these posts ve...\n",
      "2  INTP  ['Good one  _____   https://www.youtube.com/wa...\n",
      "3  INTJ  ['Dear INTP,   I enjoyed our conversation the ...\n",
      "4  ENTJ  ['You're fired., That's another silly misconce...\n"
     ]
    }
   ],
   "source": [
    "# Split posts into lists\n",
    "data['posts'] = data['posts'].apply(lambda x: x.split('|||'))\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenization + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts\n",
      "0  INFJ  [, , enfp and intj moments sportscenter not to...\n",
      "1  ENTP  [Im finding the lack of me in these posts very...\n",
      "2  INTP  [Good one, Of course to which say know thats m...\n",
      "3  INTJ  [Dear INTP enjoyed our conversation the other ...\n",
      "4  ENTJ  [Youre fired, Thats another silly misconceptio...\n"
     ]
    }
   ],
   "source": [
    "# Now that the data has been split into individual posts, we can start cleaning that and then tokenizing it\n",
    "# we can use the tokeniser on each post from each row\n",
    "\n",
    "# As there are also some links and special characters in the posts, we can remove them using regex\n",
    "\n",
    "# Clean and preprocess text\n",
    "def clean_text(text):\n",
    "    # Remove links\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove special characters and digits (including spaces)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove single characters\n",
    "    text = ' '.join([w for w in text.split() if len(w) > 1])\n",
    "    return text\n",
    "\n",
    "data['posts'] = data['posts'].apply(lambda x: [clean_text(post) for post in x])\n",
    "\n",
    "# Display cleaned posts\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE NLTK TO REMOVE STOPWORDS - Manya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenised and padded data for train:\n",
      "[[2091 2092  667 2093 2094  668 2095 2096 2097 2098 2099 2100 2101 2102\n",
      "  2103  432 2104 2105    1 2106 2107 2108 2109 2110 2111 2112 2113 2114\n",
      "  2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128\n",
      "  2129 2130  669 2131 2132 2133 2134 2135    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [2136 2137 2138  670 2139 2140 2141 2142 2143 2144  143 2145 2146 2147\n",
      "  2148 2149 2150 2151 2152 2153 2154 2155  671 2156 2157 2158 2159 2160\n",
      "  2161 2162 2163 2164 2165 2166 2167 2168  300 2169 2170 2171 2172 2173\n",
      "  2174 2175 2176 2177 2178 2179 2180 2181    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195\n",
      "  2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209\n",
      "  2210  433 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222\n",
      "  2223 2224 2225  200 2226 2227 2228 2229    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [2230 2231 2232 2233 2234 2235  170 2236 2237 2238 2239 2240 2241 2242\n",
      "  2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 2253 2254 2255 2256\n",
      "  2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 2270\n",
      "  2271 2272 2273 2274 2275 2276 2277 2278    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]\n",
      " [2279 2280 2281    1 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291\n",
      "  2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305\n",
      "  2306 2307 2308 2309 2310 2311 2312 2313 2314    1 2315 2316 2317 2318\n",
      "  2319 2320    1 2321 2322 2323    1 2324    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0]]\n",
      "The shape is  (6900, 100)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "trainData, testData = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now we can tokenize the data\n",
    "\n",
    "# We should tokenise each post in each row of the data and then pad the sequences\n",
    "# This will allow us to feed the data into the model\n",
    "\n",
    "# Given that we want to create train and test variables to store the tokenised data, we should store them as such\n",
    "\n",
    "train = trainData['posts']\n",
    "test = testData['posts']\n",
    "\n",
    "# We can now fit the tokenizer on the training and test data\n",
    "# Tokenization and sequence padding\n",
    "tokenizer_train = Tokenizer()\n",
    "tokenizer_train.fit_on_texts(trainData['posts'])\n",
    "tokenizer_test = Tokenizer()\n",
    "tokenizer_test.fit_on_texts(testData['posts'])\n",
    "\n",
    "trainSequences = tokenizer_train.texts_to_sequences(trainData['posts'])\n",
    "testSequences = tokenizer_test.texts_to_sequences(testData['posts'])\n",
    "\n",
    "maxlen = 100\n",
    "trainSeq = pad_sequences(trainSequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "testSeq = pad_sequences(testSequences, maxlen=maxlen, padding='post', truncating='post')\n",
    "\n",
    "# Displaying the data to ensure that it has been tokenised and padded correctly\n",
    "print(\"tokenised and padded data for train:\")\n",
    "# Print the first 5 rows of the data\n",
    "print(trainSeq[:5])\n",
    "\n",
    "print(\"The shape is \", trainSeq.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "INFP    1823\n",
       "INFJ    1460\n",
       "INTP    1297\n",
       "INTJ    1083\n",
       "ENTP     684\n",
       "ENFP     672\n",
       "ISTP     335\n",
       "ISFP     269\n",
       "ENTJ     228\n",
       "ISTJ     202\n",
       "ENFJ     190\n",
       "ISFJ     165\n",
       "ESTP      88\n",
       "ESFP      48\n",
       "ESFJ      42\n",
       "ESTJ      39\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 9,  0,  9, ..., 10, 10,  1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encode MBTI type labels\n",
    "labelEnc = LabelEncoder()\n",
    "labelEnc.fit(data['type'])\n",
    "\n",
    "trainLabels = labelEnc.transform(trainData['type'])\n",
    "testLabels = labelEnc.transform(testData['type'])\n",
    "\n",
    "# Display encoded labels and their counts in the training data\n",
    "display(data['type'].value_counts())\n",
    "display(trainLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "embedding_dim = 100\n",
    "lstm_units = 128\n",
    "num_classes = len(labelEnc.classes_)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer_train.word_index) + 1, embedding_dim))\n",
    "model.add(LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.1889 - loss: 2.3515 - val_accuracy: 0.1826 - val_loss: 2.2572\n",
      "Epoch 2/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.1892 - loss: 2.3122 - val_accuracy: 0.1826 - val_loss: 2.2504\n",
      "Epoch 3/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 81ms/step - accuracy: 0.1884 - loss: 2.2987 - val_accuracy: 0.2232 - val_loss: 2.2510\n",
      "Epoch 4/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step - accuracy: 0.1953 - loss: 2.3009 - val_accuracy: 0.2232 - val_loss: 2.2482\n",
      "Epoch 5/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 83ms/step - accuracy: 0.1939 - loss: 2.3059 - val_accuracy: 0.2232 - val_loss: 2.2560\n",
      "Epoch 6/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 84ms/step - accuracy: 0.1979 - loss: 2.2941 - val_accuracy: 0.2232 - val_loss: 2.2493\n",
      "Epoch 7/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 85ms/step - accuracy: 0.1950 - loss: 2.3170 - val_accuracy: 0.2232 - val_loss: 2.2503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x35666d940>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "optimizer = RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "validation_split = 0.2\n",
    "patience = 3\n",
    "\n",
    "model.fit(trainSeq, trainLabels, epochs=num_epochs, batch_size=batch_size,\n",
    "          validation_split=validation_split, callbacks=[EarlyStopping(patience=patience)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.2260 - loss: 2.3150\n",
      "Test Loss: 2.2814767360687256\n",
      "Test Accuracy: 0.2278260886669159\n"
     ]
    }
   ],
   "source": [
    "testLoss, testAcc = model.evaluate(testSeq, testLabels)\n",
    "print(f\"Test Loss: {testLoss}\")\n",
    "print(f\"Test Accuracy: {testAcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "Accuracy: 0.2278\n",
      "Precision: 0.0519\n",
      "Recall: 0.2278\n",
      "F1-score: 0.0845\n",
      "Confusion Matrix:\n",
      "[[  0   0   0   0   0   0   0   0   0  33   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 114   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  36   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 126   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   8   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  10   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   6   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  21   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 262   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 393   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 258   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 244   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  39   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  61   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  43   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  71   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for each class\n",
    "y_pred_probabilities = model.predict(testSeq)\n",
    "\n",
    "# Convert probabilities to class labels (argmax to get the index of the highest probability)\n",
    "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(testLabels, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(testLabels, y_pred, average='weighted')\n",
    "recall = recall_score(testLabels, y_pred, average='weighted')\n",
    "f1 = f1_score(testLabels, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(testLabels, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of folds\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize StratifiedKFold for classification\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define number of folds\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize StratifiedKFold for classification\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store evaluation metrics across folds\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for train_idx, val_idx in skf.split(data['posts'], data['type']):\n",
    "    # Split data into train and validation sets based on fold indices\n",
    "    X_train, X_val = data['posts'][train_idx], data['posts'][val_idx]\n",
    "    y_train, y_val = data['type'][train_idx], data['type'][val_idx]\n",
    "\n",
    "    # Encode MBTI type labels to numeric labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_val_encoded = label_encoder.transform(y_val)\n",
    "\n",
    "    # Tokenization and Padding\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    max_len = 100  # Adjust max length as needed\n",
    "\n",
    "    X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "    X_val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "    X_train_padded = pad_sequences(X_train_sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "    X_val_padded = pad_sequences(X_val_sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "    # Define and compile LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_len))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))  # Output layer with number of classes\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Train LSTM model\n",
    "    model.fit(X_train_padded, y_train_encoded, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "    # Evaluate LSTM model on validation data\n",
    "    y_pred_encoded = np.argmax(model.predict(X_val_padded), axis=1)\n",
    "\n",
    "    # Decode predicted labels back to MBTI types\n",
    "    y_pred_decoded = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "    # Calculate evaluation metrics for this fold\n",
    "    accuracy = accuracy_score(y_val, y_pred_decoded)\n",
    "    precision = precision_score(y_val, y_pred_decoded, average='weighted')\n",
    "    recall = recall_score(y_val, y_pred_decoded, average='weighted')\n",
    "    f1 = f1_score(y_val, y_pred_decoded, average='weighted')\n",
    "    conf_matrix = confusion_matrix(y_val, y_pred_decoded)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    accuracies.append(accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    confusion_matrices.append(conf_matrix)\n",
    "\n",
    "    # Print or display metrics for this fold\n",
    "    print(f\"Fold Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "# Calculate average metrics across all folds\n",
    "avg_accuracy = np.mean(accuracies)\n",
    "avg_precision = np.mean(precisions)\n",
    "avg_recall = np.mean(recalls)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "\n",
    "# Print or display average metrics across all folds\n",
    "print(\"\\nAverage Metrics Across Folds:\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1-score: {avg_f1:.4f}\")\n",
    "\n",
    "# Display average confusion matrix\n",
    "avg_conf_matrix = np.mean(confusion_matrices, axis=0)\n",
    "print(\"Average Confusion Matrix:\")\n",
    "print(avg_conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
